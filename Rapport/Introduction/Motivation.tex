\section{Motivation}
When the human genome project (a project which had the goal of sequencing 
all 22 chromosomes of the human genome) was launched in 1990, the project was 
budgeted to cost 3 billion dollars and was estimated to take fifteen years 
to complete. However as technology progressed, the project managed to complete 
its goal two years earlier than expected, in 2003. This was made possible 
because of the rapid advancements in genome sequencing, and the advancement 
hasn't stopped since. This has lead to decreasing costs of sequencing RNA and DNA, 
meaning biologists has access to greater amounts of data than ever before. 
However the technology to process these amounts of data haven't progressed at 
the same pace as sequencing has. A tool for this is scan\_for\_matches, a 
pattern-matching tool that searches through text files to match a pattern specified 
by a user. While scan\_for\_matches has proven to be a fast and reliable 
tool, because of the amount of data it shifts through, a faster alternative 
is desired.\\\\
After hearing about this problem, we thought that there must be a better 
way of searching through text that is also theoretically sound. Our first 
thought was using automata-based searching methods, since this provides a 
calculable best- and worst-case run time while being theoretically sound. 
Since regular expressions uses an automata-based way of searching, we hypothesized 
that implementing regular expressions that would have the same functions as 
scan\_for\_matches would lead to faster run times.
